{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9699d7a6-5900-4187-8399-e51b7d999359",
   "metadata": {},
   "source": [
    "# 1. DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e601cc05-25f1-46c9-bd0d-d444f61215ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "import numpy as np\n",
    "import argparse\n",
    "from Dataset import FairytalesDataset\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from train import save_checkpoint, load_checkpoint, train\n",
    "from models import basic_model\n",
    "from test import predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e16d3df-70a6-4875-8f86-36e299196ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 53,   9,  73,   6,  19, 149,  40]), tensor([  9,  73,   6,  19, 149,  40,  93]))\n"
     ]
    }
   ],
   "source": [
    "DIR_PATH = \"data/fairytales.txt\"\n",
    "START_TOKEN = \"<s>\"\n",
    "END_TOKEN = \"</s>\"\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--max-epochs', type=int, default=2)\n",
    "parser.add_argument('--batch-size', type=int, default=256)\n",
    "parser.add_argument('--sequence_length', type=int, default=7)\n",
    "args, unknown = parser.parse_known_args()\n",
    "\n",
    "dataset = FairytalesDataset(DIR_PATH, START_TOKEN, END_TOKEN, args)\n",
    "print(dataset.__getitem__(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fe765a-df1b-4488-b3ab-c1756eff2814",
   "metadata": {},
   "source": [
    "# 2. MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503a9c99-d7ee-4a61-b77e-89b7456985f5",
   "metadata": {},
   "source": [
    "Standard lstm model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93a26023-f05b-4372-9193-2b272a9cdeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Loading checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [01:08<00:00,  2.13it/s, loss=0.521]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m EPOCH 1: \u001b[0m Mean loss 1.939, \u001b[0m Perplexity 6.952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [01:09<00:00,  2.11it/s, loss=0.493]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m EPOCH 2: \u001b[0m Mean loss 1.932, \u001b[0m Perplexity 6.906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([1.93909981683509, 1.9323197333780053],\n",
       " [6.952489638760287e+00, 6.9055106195771945])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = basic_model(dataset)\n",
    "train(dataset, model, args, load_model=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a48376a-0cdf-4798-82b5-25bb55fbdf35",
   "metadata": {},
   "source": [
    "# 3. TESTING "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8e2ec4-5e2b-466a-bd53-382a6df45d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> there was once a king son who stood then the girl are talking carefully into the neighbouring swineherd barred </s> <s> but even will me you all she heard in a advice aches that paperarello asked on the lame seas </s> <s> the did would did a spot who is in kungla swimming </s> <s> then finding dreamed himself </s> <s> then you a ship replied you wish him you will never be had anything should be </s> <s> day they held him and fro out to cry where paperarello had gave it a thousand ropes and wife and he counted the princess </s>\n"
     ]
    }
   ],
   "source": [
    "print(predict(dataset, model, text='<s> there was once'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd60b12e-7504-4070-9783-6628d690d0bf",
   "metadata": {},
   "source": [
    "# 4. METRIC "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b3baf3-fcc2-47c3-9bdc-12c30771c978",
   "metadata": {},
   "source": [
    "## 4.1. BLEU Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08906e68-7d0b-4298-b8d3-c6dcc1c33ac8",
   "metadata": {},
   "source": [
    "BLEU is a precision focused metric that. calculates n-gram overlap of the reference and generated texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8aaf33e-7077-4453-ac76-562064c5762b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import SmoothingFunction, corpus_bleu, sentence_bleu\n",
    "\n",
    "def bleu(\n",
    "    ref, \n",
    "    gen,\n",
    "    weights=(1, 0, 0, 0)\n",
    "): \n",
    "    \n",
    "    \"\"\"\n",
    "    Implements the BLEU evaluation metric using nltk \n",
    "    \n",
    "    Input: \n",
    "        ref(list): reference sentences\n",
    "        gen(list): generated sentences\n",
    "        weights(tuple): customized weights to evaluate the text with\n",
    "    higher/lower order ngrams.\n",
    "        \n",
    "    Output: \n",
    "        bleu_score(float): the bleu score\n",
    "        \n",
    "    \"\"\"\n",
    "    reference = ref.split(\" \")\n",
    "    generated = gen.split(\" \")\n",
    "    ref_bleu = [] \n",
    "    gen_bleu = [] \n",
    "    for sentence in generated: \n",
    "        gen_bleu.append(sentence.split()) \n",
    "        \n",
    "    for idx, sentence in enumerate(reference): \n",
    "        ref_bleu.append([sentence.split()]) \n",
    "    \n",
    "    print(len(gen_bleu))\n",
    "    print(len(ref_bleu))\n",
    "    \n",
    "    chencherry = SmoothingFunction() \n",
    "    score_bleu = corpus_bleu(ref_bleu, gen_bleu, weights, \n",
    "                             smoothing_function=chencherry.method4)\n",
    "    \n",
    "    return score_bleu\n",
    "    \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da5d58fe-2abe-49df-bc80-ed1e80163517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:\n",
      " \n",
      "<s> lovely ilonka pursued said silent first sprang on her long ago before still this stream man in your </s>\n"
     ]
    }
   ],
   "source": [
    "generated = predict(dataset, model, text='<s> lovely ilonka', next_words=16)\n",
    "\n",
    "print('Generated:')\n",
    "print(' ') \n",
    "print(generated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db07295d-27e3-457c-a30c-65ae67d08b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference:\n",
      " \n",
      "<s> lovely ilonka there was once a man son who which so it so there will herself a desert </s>\n"
     ]
    }
   ],
   "source": [
    "vocab = dataset.words\n",
    "words = vocab[:19]\n",
    "reference =  ' '.join(words)\n",
    "reference2 = '<s> lovely ilonka there was once a man son who which so it so there will herself a desert </s>'\n",
    "print('Reference:')\n",
    "print(' ') \n",
    "print(reference2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "601fb00d-7249-4363-a7b1-2cec69671451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "b = bleu(generated, reference2)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36a243d-ec73-4128-af06-a841367ec5c0",
   "metadata": {},
   "source": [
    "## 4.2. Perplexity "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4803aa-e668-4e27-842f-4583d5afedd0",
   "metadata": {},
   "source": [
    "Training: 80%\n",
    "Validation: 10% \n",
    "Test: 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98d2350-ebbc-4d1a-8be6-71c431e521f0",
   "metadata": {},
   "source": [
    "**Perplexity** refers to the power of a probability distribution to predict, or assign probabilities, to a sample. \n",
    "\n",
    "Lower the perplexity value, the better the model. \n",
    "\n",
    "If the model is completely dumb(worst possible), perplexity = |v| i.e. size of the vocabulary.\n",
    "\n",
    "Perplexity is model dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f42a1b4-8655-4875-b87b-1cf3c486cec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = 1 # log cannot take 0 \n",
    "sent_perplexity = []"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
